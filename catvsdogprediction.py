# -*- coding: utf-8 -*-
"""CatvsDogPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GG_rBJ3pe5PO07uXgSQorvP_IkST64JH
"""

from google.colab import files
PATH=files.upload()

import torch.nn as nn
import torch
from torchvision import transforms
from torch.utils.data import Dataset,ConcatDataset,DataLoader
from PIL import Image
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
import matplotlib.pyplot as plt

class Net(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1=nn.Conv2d(3,16,kernel_size=3,padding=1)
    self.conv1_batchnorm=nn.BatchNorm2d(num_features=16)
    self.act1=nn.Tanh()
    self.pool1=nn.MaxPool2d(2)#128
    self.conv1_dropout=nn.Dropout2d(p=0.2)

    
    self.conv2=nn.Conv2d(16,64,kernel_size=3,padding=1)
    self.conv2_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act2=nn.Tanh()
    self.pool2=nn.MaxPool2d(2)#64
    self.conv2_dropout=nn.Dropout2d(p=0.2)

    
    self.conv3=nn.Conv2d(64,128,kernel_size=3,padding=1)
    self.conv3_batchnorm=nn.BatchNorm2d(num_features=128)
    self.act3=nn.Tanh()
    self.pool3=nn.MaxPool2d(2)#32
    self.conv3_dropout=nn.Dropout2d(p=0.2)

    
    self.conv4=nn.Conv2d(128,16,kernel_size=3,padding=1)
    self.conv4_batchnorm=nn.BatchNorm2d(num_features=16)
    self.act4=nn.Tanh()
    self.pool4=nn.MaxPool2d(2)#16
    self.conv4_dropout=nn.Dropout2d(p=0.2)

    self.conv5=nn.Conv2d(16,8,kernel_size=3,padding=1)
    self.conv5_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act5=nn.Tanh()
    self.pool5=nn.MaxPool2d(2)#8
    self.conv5_dropout=nn.Dropout2d(p=0.2)

    self.conv6=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv6_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act6=nn.Tanh()
    self.pool6=nn.MaxPool2d(2)#4
    self.conv6_dropout=nn.Dropout2d(p=0.2)

    self.conv7=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv7_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act7=nn.Tanh()
    self.pool7=nn.MaxPool2d(2)#2
    self.conv7_dropout=nn.Dropout2d(p=0.2)

    self.conv8=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv8_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act8=nn.Tanh()
    self.pool8=nn.MaxPool2d(2)#1
    self.conv8_dropout=nn.Dropout2d(p=0.2)

    self.fc1=nn.Linear(8*1*1,64)
    self.act9=nn.Tanh()
    self.fc2=nn.Linear(64,2)

  def forward(self,x):
    out=self.pool1(self.act1(self.conv1_batchnorm(self.conv1(x))))
    out=self.conv1_dropout(out)
    
    out=self.pool2(self.act2(self.conv2_batchnorm(self.conv2(out))))
    out=self.conv2_dropout(out)
    
    out=self.pool3(self.act3(self.conv3_batchnorm(self.conv3(out))))
    out=self.conv2_dropout(out)
    
    out=self.pool4(self.act4(self.conv4_batchnorm(self.conv4(out))))
    out=self.conv4_dropout(out)
    
    out=self.pool5(self.act5(self.conv5_batchnorm(self.conv5(out))))
    out=self.conv5_dropout(out)
    
    out=self.pool6(self.act6(self.conv6_batchnorm(self.conv6(out))))
    out=self.conv6_dropout(out)
    
    out=self.pool7(self.act7(self.conv7_batchnorm(self.conv7(out))))
    out=self.conv7_dropout(out)
    
    out=self.pool8(self.act8(self.conv8_batchnorm(self.conv8(out))))
    out=self.conv8_dropout(out)
    
    out=out.view(-1,8*1*1)
    
    out=self.act5(self.fc1(out))
    out=self.fc2(out)
    return out

model=Net()

test_transforms=transforms.Compose([transforms.Resize(256),transforms.ColorJitter(),transforms.RandomCrop(224),transforms.RandomHorizontalFlip(),transforms.Resize(256),transforms.ToTensor()])

test_transforms

from google.colab import files
fil=files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle 
!cp kaggle.json ~/.kaggle/

!kaggle competitions download -c dogs-vs-cats

!unzip train.zip

!unzip test1.zip

import os
train_dir='/content/train'
test_dir='/content/test1'
train_files=os.listdir(train_dir)
test_files=os.listdir(test_dir)
print(len(test_files))

class CatDogDataset(Dataset):
  def __init__(self,file_list,dir,mode='train',transform=None):
    self.file_list=file_list
    self.dir=dir
    self.transform=transform
    self.mode=mode
    if self.mode == 'train':
      if 'dog' in self.file_list[0]:
        self.label=1
      else:
        self.label=0

  def __len__(self):
    return len(self.file_list)

  def __getitem__(self,idx):
    img=Image.open(os.path.join(self.dir,self.file_list[idx]))
    if self.transform:
      img=self.transform(img)
      
    if self.mode == 'train':
      img=img.numpy()
      img /= 255.0
      return img.astype('float32'),self.label
    else:
      img=img.numpy()
      img /= 255.0
      return img.astype('float32'),self.file_list[idx]

testset = CatDogDataset(test_files, test_dir, mode='test', transform = test_transforms)

testloader = DataLoader(testset, batch_size = 32, shuffle=False, num_workers=4)

device = 'cuda'

device = torch.device("cuda")
model.load_state_dict(torch.load('model11.pt'))
model.to(device)

model.eval()

fn_list = []
pred_list = []
for x,fn in testloader:
    with torch.no_grad():
        x = x.to(device)
        output = model(x)
        pred = torch.argmax(output, dim=1)
        #print(fn)
        fn_list += [n[:-4] for n in fn]
        pred_list += [p.item() for p in pred]

print(fn_list)
print(pred_list)

catdogs=CatDogDataset(test_files,test_dir,transform=test_transforms)

img,_=catdogs[10090]
imagee=img
plt.imshow(img[0],cmap='gray')

img = torch.from_numpy(img)
img=img.unsqueeze(0)

img=img.to(device)
output=model(img)
pred = torch.argmax(output, dim=1)
pred= pred.item()
ad = {0:'cat', 1:'dog'}
plt.title(ad[pred])
plt.imshow(imagee[0])

from google.colab import files
im=files.upload()

img=Image.open('hal21.jpg')
img=test_transforms(img)
img=img.numpy()
img /= 255.0
img=img.astype('float32')

imagee=img
plt.imshow(img[0],cmap='gray')

img = torch.from_numpy(img)
img=img.unsqueeze(0)

device = 'cuda'

device = torch.device("cuda")
model.load_state_dict(torch.load('model11.pt'))
model.to(device)

model.eval()

img=img.to(device)
output=model(img)
pred = torch.argmax(output, dim=1)
pred= pred.item()
ad = {0:'cat', 1:'dog'}
plt.title(ad[pred])
plt.imshow(imagee[0])

