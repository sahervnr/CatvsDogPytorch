# -*- coding: utf-8 -*-
"""CatsVsDogsPytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bFm4A3hjVhB1shYrLzCzIgW47BO37MYX
"""

from google.colab import files
fil=files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle 
!cp kaggle.json ~/.kaggle/

!kaggle competitions download -c dogs-vs-cats

!unzip train.zip

!unzip test1.zip

import os
train_dir='/content/train'
test_dir='/content/test1'
train_files=os.listdir(train_dir)
test_files=os.listdir(test_dir)

from torch.utils.data import Dataset,ConcatDataset,DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import torchvision
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
import torch.nn as nn
import torch.nn.functional as F
import torch

class CatDogDataset(Dataset):
  def __init__(self,file_list,dir,mode='train',transform=None):
    self.file_list=file_list
    self.dir=dir
    self.transform=transform
    self.mode=mode
    if self.mode == 'train':
      if 'dog' in self.file_list[0]:
        self.label=1
      else:
        self.label=0

  def __len__(self):
    return len(self.file_list)

  def __getitem__(self,idx):
    img=Image.open(os.path.join(self.dir,self.file_list[idx]))
    if self.transform:
      img=self.transform(img)
      
    if self.mode == 'train':
      img=img.numpy()
      img /= 255.0
      return img.astype('float32'),self.label
    else:
      img=img.numpy()
      img /= 255.0
      return img.astype('float32'),seld.file_list[idx]

data_transform=transforms.Compose([transforms.Resize(256),transforms.ColorJitter(),transforms.RandomCrop(224),transforms.RandomHorizontalFlip(),transforms.Resize(256),transforms.ToTensor()])

data_transform

cat_files=[tf for tf in train_files if 'cat' in tf]
dog_files=[tf for tf in train_files if 'dog' in tf]

cats=CatDogDataset(cat_files,train_dir,transform=data_transform)
dogs=CatDogDataset(dog_files,train_dir,transform=data_transform)

catdogs=ConcatDataset([cats,dogs])
catdogs

img,label=catdogs[14600]
img.shape,label

plt.imshow(img[0],cmap='gray')

def split_indices(n,val_pct):
  n_val=int(val_pct*n)
  idxs=np.random.permutation(n)
  return idxs[n_val:],idxs[:n_val]

train_indices,val_indices=split_indices(len(catdogs),val_pct=0.2)
print(len(train_indices),len(val_indices))
print('Sample val indices: ',val_indices[:20])

batch_size=64
train_sampler=SubsetRandomSampler(train_indices)
train_dl=DataLoader(catdogs,batch_size,sampler=train_sampler)
valid_sampler=SubsetRandomSampler(val_indices)
valid_dl=DataLoader(catdogs,batch_size,sampler=valid_sampler)

img,_=catdogs[14600]
conv=nn.Conv2d(3,16,kernel_size=3,padding=1)
tan=nn.Tanh()
rel=nn.ReLU()
maxy=nn.MaxPool2d(2)
img = torch.from_numpy(img)
output=conv(img.unsqueeze(0))
output1=tan(output)
output11=maxy(output1)
output2=rel(output)
output22=maxy(output2)
img.unsqueeze(0).shape,output22.shape

plt.imshow(output[0,0].detach(),cmap='gray')
plt.show()

plt.imshow(output11[0,0].detach(),cmap='gray')
plt.show()

plt.imshow(output22[0,0].detach(),cmap='gray')
plt.show()

class Net(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1=nn.Conv2d(3,16,kernel_size=3,padding=1)
    self.conv1_batchnorm=nn.BatchNorm2d(num_features=16)
    self.act1=nn.Tanh()
    self.pool1=nn.MaxPool2d(2)#128
    self.conv1_dropout=nn.Dropout2d(p=0.2)

    
    self.conv2=nn.Conv2d(16,64,kernel_size=3,padding=1)
    self.conv2_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act2=nn.Tanh()
    self.pool2=nn.MaxPool2d(2)#64
    self.conv2_dropout=nn.Dropout2d(p=0.2)

    
    self.conv3=nn.Conv2d(64,128,kernel_size=3,padding=1)
    self.conv3_batchnorm=nn.BatchNorm2d(num_features=128)
    self.act3=nn.Tanh()
    self.pool3=nn.MaxPool2d(2)#32
    self.conv3_dropout=nn.Dropout2d(p=0.2)

    
    self.conv4=nn.Conv2d(128,16,kernel_size=3,padding=1)
    self.conv4_batchnorm=nn.BatchNorm2d(num_features=16)
    self.act4=nn.Tanh()
    self.pool4=nn.MaxPool2d(2)#16
    self.conv4_dropout=nn.Dropout2d(p=0.2)

    self.conv5=nn.Conv2d(16,8,kernel_size=3,padding=1)
    self.conv5_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act5=nn.Tanh()
    self.pool5=nn.MaxPool2d(2)#8
    self.conv5_dropout=nn.Dropout2d(p=0.2)

    self.conv6=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv6_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act6=nn.Tanh()
    self.pool6=nn.MaxPool2d(2)#4
    self.conv6_dropout=nn.Dropout2d(p=0.2)

    self.conv7=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv7_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act7=nn.Tanh()
    self.pool7=nn.MaxPool2d(2)#2
    self.conv7_dropout=nn.Dropout2d(p=0.2)

    self.conv8=nn.Conv2d(8,8,kernel_size=3,padding=1)
    self.conv8_batchnorm=nn.BatchNorm2d(num_features=8)
    self.act8=nn.Tanh()
    self.pool8=nn.MaxPool2d(2)#1
    self.conv8_dropout=nn.Dropout2d(p=0.2)

    self.fc1=nn.Linear(8*1*1,64)
    self.act9=nn.Tanh()
    self.fc2=nn.Linear(64,2)

  def forward(self,x):
    out=self.pool1(self.act1(self.conv1_batchnorm(self.conv1(x))))
    out=self.conv1_dropout(out)
    
    out=self.pool2(self.act2(self.conv2_batchnorm(self.conv2(out))))
    out=self.conv2_dropout(out)
    
    out=self.pool3(self.act3(self.conv3_batchnorm(self.conv3(out))))
    out=self.conv2_dropout(out)
    
    out=self.pool4(self.act4(self.conv4_batchnorm(self.conv4(out))))
    out=self.conv4_dropout(out)
    
    out=self.pool5(self.act5(self.conv5_batchnorm(self.conv5(out))))
    out=self.conv5_dropout(out)
    
    out=self.pool6(self.act6(self.conv6_batchnorm(self.conv6(out))))
    out=self.conv6_dropout(out)
    
    out=self.pool7(self.act7(self.conv7_batchnorm(self.conv7(out))))
    out=self.conv7_dropout(out)
    
    out=self.pool8(self.act8(self.conv8_batchnorm(self.conv8(out))))
    out=self.conv8_dropout(out)
    
    out=out.view(-1,8*1*1)
    
    out=self.act5(self.fc1(out))
    out=self.fc2(out)
    return out

model=Net()

for t in model.parameters():
  print(t.shape)

for images,labels in train_dl:
  print(images.shape)
  out=model(images)
  print(out.shape)
  print(out[0])
  break

F.softmax(out[0])

torch.cuda.is_available()

def get_default_device():
  if torch.cuda.is_available():
    return torch.device('cuda')
  else:
    return torch.device('cpu')

device=get_default_device()
device

def to_device(data,device):
  if isinstance(data,(list,tuple)):
    return [to_device(x,device)for x in data]
  return data.to(device,non_blocking=True)

for images,labels in train_dl:
  print(images.shape)
  images=to_device(images,device)
  print(images.device)
  break

class DeviceDataLoader():
  def __init__(self,dl,device):
    self.dl=dl
    self.device=device

  def __iter__(self):
    for b in self.dl:
      yield to_device(b,self.device)
  def __len__(self):
    return len(self.dl)

train_dl=DeviceDataLoader(train_dl,device)
valid_dl=DeviceDataLoader(valid_dl,device)

for xb,yb in valid_dl:
  print(xb.shape)
  print(yb.shape)
  break

def evaluate(model,loss_fn,valid_dl,metric=None):
  with torch.no_grad():
    results=[loss_batch(model,loss_fn,xb,yb,metric=metric)for xb,yb in valid_dl]
    #print(results)
    losses,nums,metrics=zip(*results)
    total=np.sum(nums)
    avg_loss=np.sum(np.multiply(losses,nums))/total
    avg_metric=None
    if metric is not None:
      avg_metric=np.sum(np.multiply(metrics,nums))/total
  return avg_loss,total,avg_metric

def loss_batch(model,loss_func,xb,yb,opt=None,metric=None):
  preds=model(xb)
  #print(preds.shape,yb.shape)
  loss=loss_func(preds,yb)

  if opt is not None:
    loss.backward()
    opt.step()
    opt.zero_grad()

  metric_result=None
  if metric is not None:
    metric_result=metric(preds,yb)
  return loss.item(),len(xb),metric_result

def fit(epochs,lr,model,loss_fn,train_dl,valid_dl,metric=None,opt_fn=None):
  losses,metrics=[],[]
  if opt_fn is None:opt_fn=torch.optim.Adam
  opt=torch.optim.Adam(model.parameters(),lr=lr)

  for epoch in range(epochs):
    for xb,yb in train_dl:
      loss,_,_=loss_batch(model,loss_fn,xb,yb,opt)

    result=evaluate(model,loss_fn,valid_dl,metric)
    val_loss,total,val_metric=result

    losses.append(val_loss)
    metrics.append(val_metric)

    if metric is None:
      print('Epoch [{}/{}],Loss: {:.4f'.format(epoch+1,epochs,val_loss))
    else:
      print('Epoch [{}/{}],Loss: {:.4f}, Accuracy {:.4f}'.format(epoch+1,epochs,val_loss,val_metric))
  
  return losses,metrics

def accuracy(outputs,labels):
  _,preds=torch.max(outputs,dim=1)
  return torch.sum(preds==labels).item()/len(preds)

to_device(model,device)

val_loss,total,val_acc=evaluate(model,F.cross_entropy,valid_dl,metric=accuracy)
print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss,val_acc))

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model1.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model2.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model3.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model4.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model5.pt')

losses1,metrics1=fit(10,0.1,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.1,model,F.cross_entropy,train_dl,valid_dl,accuracy)

from google.colab import files
PATH=files.upload()

device = torch.device("cuda")
model.load_state_dict(torch.load('model5.pt'))
model.to(device)

model.eval()

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model6.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model7.pt')

PATH=files.upload()

device = torch.device("cuda")
model.load_state_dict(torch.load('model10.pt'))
model.to(device)
model.eval()

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model8.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model9.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model10.pt')

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

from google.colab import files
PATH=files.upload()

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses1,metrics1=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model11.pt')

